{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f738eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import timm\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pickle\n",
    "\n",
    "plt.rcParams[\"font.family\"] = [\"Arial\", \"sans-serif\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e188b4",
   "metadata": {},
   "source": [
    "数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a779fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"获取可用的计算设备\"\"\"\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def batch_extract_cnn_features(image_paths, model, transform, device=None, batch_size=16):\n",
    "    \"\"\"批量提取图像的CNN特征\"\"\"\n",
    "    device = device or get_device()\n",
    "    all_features = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(image_paths), batch_size), desc=\"Feature Extraction\"):\n",
    "            batch = []\n",
    "            for path in image_paths[i:i+batch_size]:\n",
    "                try:\n",
    "                    batch.append(transform(Image.open(path).convert(\"RGB\")))\n",
    "                except:\n",
    "                    batch.append(None)\n",
    "            \n",
    "            valid_indices = [j for j, img in enumerate(batch) if img is not None]\n",
    "            if not valid_indices:\n",
    "                continue\n",
    "                \n",
    "            valid_batch = torch.stack([batch[j] for j in valid_indices]).to(device)\n",
    "            features = model(valid_batch)\n",
    "            \n",
    "            batch_features = []\n",
    "            current_idx = 0\n",
    "            for j in range(len(batch)):\n",
    "                batch_features.append([f[current_idx].cpu() for f in features] if j in valid_indices else None)\n",
    "                current_idx += 1 if j in valid_indices else 0\n",
    "            \n",
    "            all_features.extend(batch_features)\n",
    "    \n",
    "    return all_features\n",
    "\n",
    "def cosine_cnn_similarity(feat1, feat2, dim=1):\n",
    "    \"\"\"计算两个特征之间的余弦相似度\"\"\"\n",
    "    if feat1 is None or feat2 is None:\n",
    "        return None\n",
    "        \n",
    "    if len(feat1.shape) > 2:\n",
    "        feat1 = feat1.flatten(1)\n",
    "    if len(feat2.shape) > 2:\n",
    "        feat2 = feat2.flatten(1)\n",
    "    \n",
    "    feat1 = F.normalize(feat1, p=2, dim=dim)\n",
    "    feat2 = F.normalize(feat2, p=2, dim=dim)\n",
    "    \n",
    "    return torch.sum(feat1 * feat2, dim=dim).mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d0a3cd",
   "metadata": {},
   "source": [
    "数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2b9c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_human(image_path, sam_model, device=None, image_size=512, output_folder=\"segmented_images\", stability_type=None):\n",
    "    \"\"\"使用SAM模型分割人体并保存到指定文件夹，保留原文件名\"\"\"\n",
    "    device = device or get_device()\n",
    "    if sam_model is None:\n",
    "        return image_path\n",
    "    \n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        h, w = image.shape[:2]\n",
    "        if max(h, w) > image_size:\n",
    "            scale = image_size / max(h, w)\n",
    "            image = cv2.resize(image, (int(w * scale), int(h * scale)))\n",
    "            \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        predictor = SamPredictor(sam_model)\n",
    "        predictor.set_image(image)\n",
    "        \n",
    "        h, w = image.shape[:2]\n",
    "        masks, scores, _ = predictor.predict(\n",
    "            point_coords=np.array([[w//2, h//2]]),\n",
    "            point_labels=np.array([1]),\n",
    "            multimask_output=True,\n",
    "        )\n",
    "        \n",
    "        best_mask = masks[np.argmax(scores)]\n",
    "        masked_image = image.copy()\n",
    "        masked_image[~best_mask] = 0\n",
    "        \n",
    "        save_dir = os.path.join(output_folder, stability_type) if stability_type else output_folder\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        save_path = os.path.join(save_dir, os.path.basename(image_path))\n",
    "        Image.fromarray(masked_image).save(save_path)\n",
    "        return save_path\n",
    "    except:\n",
    "        return image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35942a62",
   "metadata": {},
   "source": [
    "模型初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b82c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_segments(pairs, sam_model, stability_type=\"stable\", device=None, image_size=512, \n",
    "                        batch_size=4, cache_file=None, output_folder=\"segmented_images\"):\n",
    "    \"\"\"提取所有图像的人体分割结果（支持批量处理、缓存和自定义保存路径）\"\"\"\n",
    "    device = device or get_device()\n",
    "    \n",
    "    if cache_file and os.path.exists(cache_file):\n",
    "        try:\n",
    "            with open(cache_file, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    all_paths = [path for pair in pairs for path in [pair[0]['image_path'], pair[1]['image_path']]]\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=batch_size) as executor:\n",
    "        futures = [executor.submit(segment_human, path, sam_model, device, image_size, output_folder, stability_type) \n",
    "                  for path in all_paths]\n",
    "        seg_image_paths = [future.result() for future in tqdm(futures, desc=f\"{stability_type.capitalize()} Segmentation\")]\n",
    "    \n",
    "    if cache_file:\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(cache_file), exist_ok=True)\n",
    "            with open(cache_file, 'wb') as f:\n",
    "                pickle.dump(seg_image_paths, f)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return seg_image_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fd8776",
   "metadata": {},
   "source": [
    "图像分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09750208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_visualize(stable_seg_paths, non_stable_seg_paths, num_samples=16):\n",
    "    \"\"\"从两类图像中随机抽样并可视化\"\"\"\n",
    "    if not stable_seg_paths or not non_stable_seg_paths:\n",
    "        return\n",
    "    \n",
    "    stable_samples = random.sample(stable_seg_paths, min(num_samples, len(stable_seg_paths)))\n",
    "    non_stable_samples = random.sample(non_stable_seg_paths, min(num_samples, len(non_stable_seg_paths)))\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    gs = GridSpec(4, 8, figure=fig)\n",
    "    \n",
    "    for i, path in enumerate(stable_samples):\n",
    "        ax = fig.add_subplot(gs[i//8, i%8])\n",
    "        try:\n",
    "            ax.imshow(Image.open(path))\n",
    "            ax.set_title('Stable Pairs')\n",
    "        except:\n",
    "            ax.text(0.5, 0.5, 'Failed to load', ha='center', va='center')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    for i, path in enumerate(non_stable_samples):\n",
    "        ax = fig.add_subplot(gs[2 + (i//8), i%8])\n",
    "        try:\n",
    "            ax.imshow(Image.open(path))\n",
    "            ax.set_title('Non-Stable Pairs')\n",
    "        except:\n",
    "            ax.text(0.5, 0.5, 'Failed to load', ha='center', va='center')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('Randomly Sampled Segmented Images', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.savefig('sam_segmented_samples.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77154ec1",
   "metadata": {},
   "source": [
    "特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d9112",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    \"\"\"多特征提取器，支持GLCM、ViT和ConvNeXt\"\"\"\n",
    "    \n",
    "    def __init__(self, method='convnext', model_name='convnext_base', device=device):\n",
    "        \"\"\"\n",
    "        初始化特征提取器\n",
    "        \n",
    "        参数:\n",
    "            method: 特征提取方法，可选 'glcm', 'vit', 'convnext'\n",
    "            model_name: 深度学习模型名称\n",
    "            device: 运行设备\n",
    "        \"\"\"\n",
    "        self.method = method.lower()\n",
    "        self.device = device\n",
    "        self.model = None\n",
    "        self.transform = None\n",
    "        \n",
    "        print(f\"\\n===== 初始化 {self.method.upper()} 特征提取器 =====\")\n",
    "        \n",
    "        if self.method == 'glcm':\n",
    "            print(\"使用GLCM (灰度共生矩阵) 特征提取\")\n",
    "            \n",
    "        elif self.method in ['vit', 'convnext']:\n",
    "            print(f\"使用 {self.method.upper()} 特征提取\")\n",
    "\n",
    "            if self.method == 'vit':\n",
    "                self.model = timm.create_model(\n",
    "                    'vit_base_patch16_224', \n",
    "                    pretrained=True,\n",
    "                    num_classes=0 \n",
    "                )\n",
    "            elif self.method == 'convnext':\n",
    "                self.model = timm.create_model(\n",
    "                    'convnext_base', \n",
    "                    pretrained=True,\n",
    "                    num_classes=0\n",
    "                )\n",
    "            \n",
    "            self.model.to(self.device)\n",
    "            self.model.eval()\n",
    "\n",
    "            self.transform = timm.data.create_transform(\n",
    "                **timm.data.resolve_data_config(self.model.pretrained_cfg)\n",
    "            )\n",
    "            \n",
    "            print(f\"已加载预训练 {self.method.upper()} 模型\")\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"不支持的特征提取方法: {method}。支持的方法有 'glcm', 'vit', 'convnext'\")\n",
    "    \n",
    "    def extract_features(self, image_path):\n",
    "        \"\"\"提取图像特征\"\"\"\n",
    "        try:\n",
    "            if self.method == 'glcm':\n",
    "                return self._extract_glcm_features(image_path)\n",
    "            else:\n",
    "                return self._extract_deep_features(image_path)\n",
    "        except Exception as e:\n",
    "            print(f\"特征提取失败: {image_path}, 错误: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _extract_glcm_features(self, image_path):\n",
    "        \"\"\"提取GLCM特征\"\"\"\n",
    "        img = Image.open(image_path).convert('L') \n",
    "        img = img.resize((224, 224))\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        distances = [1, 2, 3]\n",
    "        angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "        glcm = skfeature.greycomatrix(img_array, distances, angles, levels=256, symmetric=True, normed=True)\n",
    "\n",
    "        contrast = skfeature.greycoprops(glcm, 'contrast').mean()\n",
    "        dissimilarity = skfeature.greycoprops(glcm, 'dissimilarity').mean()\n",
    "        homogeneity = skfeature.greycoprops(glcm, 'homogeneity').mean()\n",
    "        energy = skfeature.greycoprops(glcm, 'energy').mean()\n",
    "        correlation = skfeature.greycoprops(glcm, 'correlation').mean()\n",
    "        asm = skfeature.greycoprops(glcm, 'ASM').mean()\n",
    "        \n",
    "        return np.array([contrast, dissimilarity, homogeneity, energy, correlation, asm])\n",
    "    \n",
    "    def _extract_deep_features(self, image_path):\n",
    "        \"\"\"提取深度学习特征\"\"\"\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_tensor = self.transform(img).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features = self.model(img_tensor)\n",
    "\n",
    "            if self.method == 'vit':\n",
    "                features = features[:, 0, :] \n",
    "            elif self.method == 'convnext':\n",
    "\n",
    "                features = F.adaptive_avg_pool2d(features, (1, 1)).flatten(1)\n",
    "        \n",
    "        return features.cpu().numpy().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d42633d",
   "metadata": {},
   "source": [
    "相似度计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a1c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarities(pairs, feature_method='convnext', model_name='convnext_base'):\n",
    "    \"\"\"计算图像对的相似度\"\"\"\n",
    "    print(f\"\\n===== 模块6: 使用 {feature_method.upper()} 计算相似度 =====\")\n",
    "    \n",
    "    if not pairs:\n",
    "        print(\"无图像对，跳过相似度计算\")\n",
    "        return [], []\n",
    "    \n",
    "    extractor = FeatureExtractor(method=feature_method, model_name=model_name, device=device)\n",
    "\n",
    "    similarities = []\n",
    "    valid_pairs = []\n",
    "    \n",
    "    print(f\"开始计算 {len(pairs)} 对图像的相似度...\")\n",
    "    \n",
    "    for i, (wood_path, clinic_path) in enumerate(pairs):\n",
    "        print(f\"({i+1}/{len(pairs)}) 处理: {os.path.basename(wood_path)} 和 {os.path.basename(clinic_path)}\")\n",
    "        \n",
    "        wood_features = extractor.extract_features(wood_path)\n",
    "        clinic_features = extractor.extract_features(clinic_path)\n",
    "        \n",
    "        if wood_features is not None and clinic_features is not None:\n",
    "            wood_tensor = torch.tensor(wood_features, dtype=torch.float32).unsqueeze(0)\n",
    "            clinic_tensor = torch.tensor(clinic_features, dtype=torch.float32).unsqueeze(0)\n",
    "            \n",
    "            similarity = F.cosine_similarity(wood_tensor, clinic_tensor).item()\n",
    "            similarities.append(similarity)\n",
    "            valid_pairs.append((wood_path, clinic_path))\n",
    "            \n",
    "            print(f\"  相似度: {similarity:.4f}\")\n",
    "        else:\n",
    "            print(f\"  无法提取特征，跳过此对\")\n",
    "    \n",
    "    print(f\"完成相似度计算: 有效对 {len(similarities)}/{len(pairs)}\")\n",
    "    \n",
    "    if similarities:\n",
    "        avg_similarity = np.mean(similarities)\n",
    "        print(f\"平均相似度: {avg_similarity:.4f}\")\n",
    "    \n",
    "    return similarities, valid_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c92556",
   "metadata": {},
   "source": [
    "结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f48b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pair_cnn_similarities(pairs, model_name='convnext_tiny', device=None, batch_size=16, image_size=224, cache_file=None):\n",
    "    \"\"\"计算多对图像的CNN特征相似度\"\"\"\n",
    "    device = device or get_device()\n",
    "    \n",
    "    if cache_file and os.path.exists(cache_file):\n",
    "        try:\n",
    "            with open(cache_file, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                return data['similarities'], data['failed_pairs']\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    wood_paths = [wood['image_path'] for wood, _ in pairs]\n",
    "    clinic_paths = [clinic['image_path'] for _, clinic in pairs]\n",
    "    all_paths = wood_paths + clinic_paths\n",
    "    \n",
    "    model = timm.create_model(model_name, pretrained=True, features_only=True, out_indices=[0, 1, 2, 3])\n",
    "    model.to(device).eval()\n",
    "    \n",
    "    data_cfg = timm.data.resolve_data_config(model.pretrained_cfg)\n",
    "    data_cfg['input_size'] = (3, image_size, image_size)\n",
    "    transform = timm.data.create_transform(**data_cfg)\n",
    "    \n",
    "    all_features = batch_extract_cnn_features(all_paths, model, transform, device, batch_size)\n",
    "    wood_features = all_features[:len(wood_paths)]\n",
    "    clinic_features = all_features[len(wood_paths):]\n",
    "    \n",
    "    similarities = []\n",
    "    failed_pairs = []\n",
    "    \n",
    "    for i, (wood_feat, clinic_feat) in enumerate(tqdm(zip(wood_features, clinic_features), total=len(pairs), desc=\"Similarity\")):\n",
    "        if wood_feat is None or clinic_feat is None:\n",
    "            failed_pairs.append(i)\n",
    "            similarities.append(None)\n",
    "            continue\n",
    "            \n",
    "        layer_similarities = [cosine_cnn_similarity(w_feat, c_feat) for w_feat, c_feat in zip(wood_feat, clinic_feat) if w_feat is not None]\n",
    "        similarities.append(np.mean(layer_similarities) if layer_similarities else None)\n",
    "    \n",
    "    valid_similarities = [s for s in similarities if s is not None]\n",
    "    \n",
    "    if cache_file:\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(cache_file), exist_ok=True)\n",
    "            with open(cache_file, 'wb') as f:\n",
    "                pickle.dump({'similarities': similarities, 'failed_pairs': failed_pairs}, f)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return valid_similarities, failed_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189d7303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    'batch_size': 4,\n",
    "    'image_size': 192,\n",
    "    'cnn_model': 'convnext_tiny',\n",
    "    'sam_image_size': 384,\n",
    "    'use_cache': True,\n",
    "    'cache_dir': 'cache',\n",
    "    'seg_output_folder': 'segmented_images'\n",
    "}\n",
    "\n",
    "device = get_device()\n",
    "if config['use_cache']:\n",
    "    os.makedirs(config['cache_dir'], exist_ok=True)\n",
    "os.makedirs(config['seg_output_folder'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1852be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('../../datasets/data.csv')\n",
    "\n",
    "stable_df = df[df['stability'] == 'stable']\n",
    "non_stable_df = df[df['stability'] == 'non-stable']\n",
    "\n",
    "stable_pairs = []\n",
    "for pair_id in stable_df['pair_id'].unique():\n",
    "    pair_images = stable_df[stable_df['pair_id'] == pair_id]\n",
    "    wood = pair_images[pair_images['image_type'] == 'wood'].iloc[0]\n",
    "    clinic = pair_images[pair_images['image_type'] == 'clinic'].iloc[0]\n",
    "    stable_pairs.append((wood, clinic))\n",
    "\n",
    "non_stable_pairs = []\n",
    "for pair_id in non_stable_df['pair_id'].unique():\n",
    "    pair_images = non_stable_df[non_stable_df['pair_id'] == pair_id]\n",
    "    wood = pair_images[pair_images['image_type'] == 'wood'].iloc[0]\n",
    "    clinic = pair_images[pair_images['image_type'] == 'clinic'].iloc[0]\n",
    "    non_stable_pairs.append((wood, clinic))\n",
    "\n",
    "print(f\"Found {len(stable_pairs)} stable pairs and {len(non_stable_pairs)} non-stable pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f000d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "try:\n",
    "    sam_checkpoint = '../../outputs/checkpoints/proposed/sam_vit_b_01ec64.pth'\n",
    "\n",
    "    if not os.path.exists(sam_checkpoint):\n",
    "        sam_checkpoint = '../../outputs/checkpoints/proposed/sam_vit_h_4b8939(1).pth'\n",
    "    \n",
    "    model_type = \"vit_b\" if \"vit_b\" in sam_checkpoint else \"vit_l\" if \"vit_l\" in sam_checkpoint else \"vit_h\"\n",
    "    sam = sam_model_registry[model_type](checkpoint=sam_checkpoint).to(device)\n",
    "except:\n",
    "    print(\"SAM model not found, using original images instead of segmentation\")\n",
    "    sam = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4132043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "non_stable_seg_cache = os.path.join(config['cache_dir'], 'non_stable_seg_paths.pkl') if config['use_cache'] else None\n",
    "\n",
    "stable_seg_paths = extract_all_segments(\n",
    "    stable_pairs, sam, \"stable\", device, \n",
    "    image_size=config['sam_image_size'], \n",
    "    batch_size=config['batch_size'],\n",
    "    cache_file=stable_seg_cache,\n",
    "    output_folder=config['seg_output_folder']\n",
    ")\n",
    "\n",
    "non_stable_seg_paths = extract_all_segments(\n",
    "    non_stable_pairs, sam, \"non-stable\", device, \n",
    "    image_size=config['sam_image_size'], \n",
    "    batch_size=config['batch_size'],\n",
    "    cache_file=non_stable_seg_cache,\n",
    "    output_folder=config['seg_output_folder']\n",
    ")\n",
    "\n",
    "\n",
    "for i, (wood, clinic) in enumerate(stable_pairs):\n",
    "    stable_pairs[i] = (\n",
    "        {'image_path': stable_seg_paths[i*2], 'pair_id': wood['pair_id'], 'image_type': wood['image_type']},\n",
    "        {'image_path': stable_seg_paths[i*2+1], 'pair_id': clinic['pair_id'], 'image_type': clinic['image_type']}\n",
    "    )\n",
    "\n",
    "for i, (wood, clinic) in enumerate(non_stable_pairs):\n",
    "    non_stable_pairs[i] = (\n",
    "        {'image_path': non_stable_seg_paths[i*2], 'pair_id': wood['pair_id'], 'image_type': wood['image_type']},\n",
    "        {'image_path': non_stable_seg_paths[i*2+1], 'pair_id': clinic['pair_id'], 'image_type': clinic['image_type']}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543fe0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_and_visualize(stable_seg_paths, non_stable_seg_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c666695",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stable_sim_cache = os.path.join(config['cache_dir'], f'stable_similarities_{config[\"cnn_model\"]}_{config[\"image_size\"]}.pkl')\n",
    "non_stable_sim_cache = os.path.join(config['cache_dir'], f'non_stable_similarities_{config[\"cnn_model\"]}_{config[\"image_size\"]}.pkl')\n",
    "\n",
    "stable_similarities, _ = compute_pair_cnn_similarities(\n",
    "    stable_pairs, \n",
    "    model_name=config['cnn_model'],\n",
    "    device=device,\n",
    "    batch_size=config['batch_size'],\n",
    "    image_size=config['image_size'],\n",
    "    cache_file=stable_sim_cache\n",
    ")\n",
    "\n",
    "non_stable_similarities, _ = compute_pair_cnn_similarities(\n",
    "    non_stable_pairs, \n",
    "    model_name=config['cnn_model'],\n",
    "    device=device,\n",
    "    batch_size=config['batch_size'],\n",
    "    image_size=config['image_size'],\n",
    "    cache_file=non_stable_sim_cache\n",
    ")\n",
    "\n",
    "if stable_similarities and non_stable_similarities:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot([stable_similarities, non_stable_similarities], \n",
    "               labels=['Stable Pairs', 'Non-Stable Pairs'], \n",
    "               patch_artist=True,\n",
    "               showmeans=True)\n",
    "    \n",
    "    plt.title('Feature Similarities Comparison')\n",
    "    plt.ylabel('Cosine Similarity')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.plot([1, 2], [np.mean(stable_similarities), np.mean(non_stable_similarities)], 'ro-', label='Mean')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('similarity_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vitiligo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
